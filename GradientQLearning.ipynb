{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdea856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux, Flux.Data, Flux.Optimise\n",
    "using Statistics, Random\n",
    "using DataFrames\n",
    "using CSV\n",
    "using Dates\n",
    "using LinearAlgebra\n",
    "\n",
    "mutable struct GradientQLearning  \n",
    "    A # action space (assumes 1:nactions) \n",
    "    y # discount \n",
    "    Q # action value function \n",
    "    gradientQ #gradient of action value function\n",
    "    theta # action value function parameter\n",
    "    alpha # learning rate \n",
    "end \n",
    "\n",
    "#create our action space\n",
    "\n",
    "# our action space is 49 6-vectors\n",
    "numActions = 49\n",
    "pos = zeros(7,3)\n",
    "ori = zeros(7,3)\n",
    "actionSpace = zeros(numActions, 6)\n",
    "\n",
    "pos_delta = 0.00005\n",
    "ori_delta = .0002\n",
    "\n",
    "count = 1;\n",
    "for i = 1:3\n",
    "    pos[count, i] = pos_delta\n",
    "    count+= 1\n",
    "    pos[count, i] = -pos_delta\n",
    "    count+= 1\n",
    "end\n",
    "# reset count\n",
    "count = 1;\n",
    "for i = 1:3\n",
    "    ori[count, i] = ori_delta\n",
    "    count+= 1\n",
    "    ori[count, i] = -ori_delta\n",
    "    count+= 1\n",
    "end\n",
    "\n",
    "# reset count\n",
    "count = 1;\n",
    "for j = 1:length(pos[:,1])\n",
    "    for k = 1:length(pos[:,1])\n",
    "        actionSpace[count, :] = vcat(pos[j, :], ori[k, :])\n",
    "        count += 1\n",
    "    end\n",
    "end\n",
    "\n",
    "# put all actions into a dictionary \n",
    "# map each action vector to an integer for indexing \n",
    "# which set of parameters we are training\n",
    "\n",
    "actionDict = Dict() \n",
    "for l = 1:length(actionSpace[:,1])\n",
    "    actionDict[actionSpace[l, :]] = l\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2af638d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "update! (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create our basis functions for our linear approximation of Q\n",
    "\n",
    "numStateComp = 18\n",
    "\n",
    "function beta(s, a)\n",
    "    idx = actionDict[a]\n",
    "    basis = zeros(1, numActions*numStateComp+1)\n",
    "    basis[numActions*numStateComp+1] = 1\n",
    "    \n",
    "    s = [s[1], s[2], s[3], s[4], s[5], s[6], s[7], s[8], s[9], \n",
    "    s[1]^2, s[2]^2, s[3]^2, s[4]^2, s[5]^2, s[6]^2, s[7]^2, s[8]^2, s[9]^2]\n",
    "    \n",
    "    basis[idx*numStateComp-numStateComp+1:idx*numStateComp] = s\n",
    "    return basis\n",
    "end\n",
    "\n",
    "Q(theta, s, a) = dot(theta, beta(s, a))\n",
    "    \n",
    "gradientQ(theta, s, a) = beta(s, a)\n",
    "\n",
    "scale_gradient(gradient, L2_max) = min(L2_max/norm(gradient), 1)*gradient\n",
    "\n",
    "function update!(model::GradientQLearning, s, a, r, s′) \n",
    "    A, y, Q, theta, alpha = model.A, model.y, model.Q, model.theta, model.alpha \n",
    "    u = maximum(Q(theta, s′, a′) for a′ in eachrow(A))\n",
    "    delta = (r + y*u - Q(theta, s, a))*model.gradientQ(theta, s, a)\n",
    "    theta[:] += (alpha*scale_gradient(delta,1))[:]\n",
    "    return model \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3babe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed iteration 10\n",
      "time elapsed 73678 milliseconds\n",
      "Completed iteration 20\n",
      "time elapsed 157171 milliseconds\n",
      "Completed iteration 30\n",
      "time elapsed 243549 milliseconds\n",
      "Completed iteration 40\n",
      "time elapsed 320164 milliseconds\n",
      "Completed iteration 50\n",
      "time elapsed 403773 milliseconds\n",
      "Completed iteration 60\n",
      "time elapsed 488593 milliseconds\n",
      "Completed iteration 70\n",
      "time elapsed 584968 milliseconds\n",
      "Completed iteration 80\n",
      "time elapsed 675618 milliseconds\n",
      "Completed iteration 90\n",
      "time elapsed 760836 milliseconds\n",
      "Completed iteration 100\n",
      "time elapsed 849311 milliseconds\n",
      "Completed iteration 110\n",
      "time elapsed 934515 milliseconds\n",
      "Completed iteration 120\n",
      "time elapsed 1022356 milliseconds\n",
      "Completed iteration 130\n",
      "time elapsed 1114290 milliseconds\n",
      "Completed iteration 140\n",
      "time elapsed 1217076 milliseconds\n",
      "Completed iteration 150\n",
      "time elapsed 1307953 milliseconds\n",
      "Completed iteration 160\n",
      "time elapsed 1410920 milliseconds\n",
      "Completed iteration 170\n",
      "time elapsed 1509986 milliseconds\n",
      "Completed iteration 180\n",
      "time elapsed 1604848 milliseconds\n",
      "Completed iteration 190\n",
      "time elapsed 1704269 milliseconds\n",
      "Completed iteration 200\n",
      "time elapsed 1812888 milliseconds\n",
      "Completed iteration 210\n",
      "time elapsed 1912726 milliseconds\n",
      "Completed iteration 220\n",
      "time elapsed 2005387 milliseconds\n",
      "Completed iteration 230\n",
      "time elapsed 2112992 milliseconds\n",
      "Completed iteration 240\n",
      "time elapsed 2215651 milliseconds\n",
      "Completed iteration 250\n",
      "time elapsed 2322728 milliseconds\n",
      "Completed iteration 260\n",
      "time elapsed 2428218 milliseconds\n",
      "Completed iteration 270\n",
      "time elapsed 2543595 milliseconds\n",
      "Completed iteration 280\n",
      "time elapsed 2659632 milliseconds\n",
      "Completed iteration 290\n",
      "time elapsed 2764366 milliseconds\n",
      "Completed iteration 300\n",
      "time elapsed 2870523 milliseconds\n",
      "Completed iteration 310\n",
      "time elapsed 2976193 milliseconds\n",
      "Completed iteration 320\n",
      "time elapsed 3090403 milliseconds\n",
      "Completed iteration 330\n",
      "time elapsed 3204870 milliseconds\n",
      "Completed iteration 340\n",
      "time elapsed 3322191 milliseconds\n",
      "Completed iteration 350\n",
      "time elapsed 3441885 milliseconds\n",
      "Completed iteration 360\n",
      "time elapsed 3552244 milliseconds\n",
      "Completed iteration 370\n",
      "time elapsed 3678665 milliseconds\n",
      "Completed iteration 380\n",
      "time elapsed 3814798 milliseconds\n",
      "Completed iteration 390\n",
      "time elapsed 3925423 milliseconds\n",
      "Completed iteration 400\n",
      "time elapsed 4036407 milliseconds\n",
      "Completed iteration 410\n",
      "time elapsed 4161412 milliseconds\n",
      "Completed iteration 420\n",
      "time elapsed 4276716 milliseconds\n",
      "Completed iteration 430\n",
      "time elapsed 4407838 milliseconds\n",
      "Completed iteration 440\n",
      "time elapsed 4537021 milliseconds\n",
      "Completed iteration 450\n",
      "time elapsed 4663269 milliseconds\n"
     ]
    }
   ],
   "source": [
    "# define our parameters and initialize our thetas\n",
    "\n",
    "theta = zeros(1, numActions*numStateComp+1)\n",
    "theta[numActions*numStateComp+1] = 1\n",
    "sub_theta = [1000, 1000, 1000, 1000, 1000, 1000, 1, 1, 1, \n",
    "    100, 100, 100, 100, 100, 100, .1, .1, .1]\n",
    "for i = 1:numActions\n",
    "    theta[i*numStateComp-numStateComp+1: i*numStateComp] = sub_theta\n",
    "end\n",
    "\n",
    "stateComponents = 9\n",
    "actionComponents = 6\n",
    "forceComponents = 3\n",
    "\n",
    "learning_rate = 0.5\n",
    "discount = 0.95\n",
    "\n",
    "model = GradientQLearning(actionSpace, discount, Q, gradientQ, theta, learning_rate)\n",
    "\n",
    "numOfTraj = 23\n",
    "total_iterations = 6000\n",
    "\n",
    "file_folder = \"./Matlab-data-cleaning/cleaned-deltaPhi-forQLearning/\"\n",
    "weights_folder = \"./dense-reward-v2-weights/\"\n",
    "\n",
    "t1 = now();\n",
    "\n",
    "for i in 1:total_iterations\n",
    "    for k in 1:numOfTraj\n",
    "        trajectory = file_folder*string(\"output\", k, \".csv\")\n",
    "        data = CSV.read(trajectory, DataFrame)\n",
    "        for row in eachrow(data) \n",
    "                row = collect(row)\n",
    "                s = row[1:stateComponents]\n",
    "                a = row[stateComponents + 1: stateComponents + actionComponents]\n",
    "                r = row[stateComponents + actionComponents + 1]\n",
    "                s′ = row[stateComponents + actionComponents + 2: end]\n",
    "                model = update!(model, s, a, r, s′)\n",
    "        end \n",
    "    end\n",
    "    if (i%10 == 0)\n",
    "        #write current weights to file\n",
    "        output_theta = DataFrame(theta, :auto)\n",
    "        file_name = weights_folder*string(\"theta_\",i,\"_dense.csv\")\n",
    "        CSV.write(file_name, output_theta)\n",
    "        \n",
    "        t2 = now();\n",
    "        println(string(\"Completed iteration \", i))\n",
    "        println(string(\"time elapsed \",(t2-t1)))\n",
    "    end\n",
    "end\n",
    "\n",
    "t2 = now();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06bcb670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91a67a65",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `theta` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `theta` not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[1]:1"
     ]
    }
   ],
   "source": [
    "theta[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27edde22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"./sparse-reward-weights/theta_10_sparse.csv\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#write current weights to file\n",
    "output_theta = DataFrame(theta, :auto)\n",
    "file_name = weights_folder*string(\"theta_\",i,\"_sparse.csv\")\n",
    "CSV.write(file_name, output_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbf905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "actionSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a430164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed iteration 10\n"
     ]
    }
   ],
   "source": [
    "i = 10\n",
    "i % 10\n",
    "println(string(\"Completed iteration \", i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d49a02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.4",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
